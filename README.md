# AI Hand Tracking & Gesture Recognition (Teachable Machine)
**Real-time Hand Gesture Recognition System using MediaPipe & KNN Classifier**

---

### üåê Project Information
**Subject:** Introduction to Artificial Intelligence (‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô)  
**Program:** B.Ind.Tech in Electrical Technology and Intelligence Control Systems (‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£ ‡∏≠‡∏™.‡∏ö.‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏≠‡∏±‡∏à‡∏â‡∏£‡∏¥‡∏¢‡∏∞)  
**Department:** Electrical Engineering, Faculty of Industry and Technology  
**University:** Rajamangala University of Technology Isan, Sakon Nakhon Campus (‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏£‡∏≤‡∏ä‡∏°‡∏á‡∏Ñ‡∏•‡∏≠‡∏µ‡∏™‡∏≤‡∏ô ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡πÄ‡∏Ç‡∏ï‡∏™‡∏Å‡∏•‡∏ô‡∏Ñ‡∏£)

**Developer / Instructor:** Nakarin Sripanya (‡∏≠.‡∏ô‡∏Ñ‡∏£‡∏¥‡∏ô‡∏ó‡∏£‡πå ‡∏®‡∏£‡∏µ‡∏õ‡∏±‡∏ç‡∏ç‡∏≤)  
**Email:** nakatin.sr@rmuti.ac.th  
**GitHub:** [https://github.com/NKSR22/AI-Hand-Gesture-Recognition](https://github.com/NKSR22/AI-Hand-Gesture-Recognition)

---

## üìñ About the Project (‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå)
**[EN]** This project is a real-time hand gesture recognition system developed using Python, MediaPipe, and OpenCV. It features a **"Teachable Machine"** capability, allowing users to train the AI to recognize custom hand gestures instantly using a K-Nearest Neighbors (KNN) algorithm without retraining the entire model.

**[TH]** ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏°‡∏∑‡∏≠‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö‡∏ô‡∏¥‡πâ‡∏ß‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå ‡∏û‡∏±‡∏í‡∏ô‡∏≤‡∏î‡πâ‡∏ß‡∏¢ Python, MediaPipe ‡πÅ‡∏•‡∏∞ OpenCV ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ö‡∏ö **"Teachable Machine"** ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÉ‡∏´‡πâ‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ "‡∏™‡∏≠‡∏ô" AI ‡πÉ‡∏´‡πâ‡∏à‡∏î‡∏à‡∏≥‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡∏°‡∏∑‡∏≠‡πÉ‡∏´‡∏°‡πà‡πÜ ‡πÑ‡∏î‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ú‡πà‡∏≤‡∏ô‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏° KNN ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏ï‡πâ‡∏ô

---

## üß† Theory & Principles (‡∏ó‡∏§‡∏©‡∏é‡∏µ‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô)

### 1. Computer Vision & Landmark Detection
**[EN]** The system utilizes **MediaPipe Hands**, a high-fidelity hand tracking solution. It employs machine learning (ML) to infer 21 3D landmarks of a hand from a single video frame.
- **Palm Detection Model:** Operates on the full image and returns an oriented hand bounding box.
- **Hand Landmark Model:** Operates on the cropped image region defined by the palm detector and returns high-fidelity 3D hand keypoints.

**[TH]** ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ **MediaPipe Hands** ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏ã‡∏•‡∏π‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏°‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ Machine Learning ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≤‡∏î‡∏Å‡∏≤‡∏£‡∏ì‡πå‡∏à‡∏∏‡∏î‡∏û‡∏¥‡∏Å‡∏±‡∏î 3 ‡∏°‡∏¥‡∏ï‡∏¥ (3D Landmarks) ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô 21 ‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏°‡∏∑‡∏≠‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
- **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ù‡πà‡∏≤‡∏°‡∏∑‡∏≠:** ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏°‡∏∑‡∏≠‡πÉ‡∏ô‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
- **‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏°‡∏∑‡∏≠:** ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô‡∏Å‡∏£‡∏≠‡∏ö‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏ï‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏°‡∏∑‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏ï‡πà‡∏≠‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î

![Hand Landmarks](https://developers.google.com/static/mediapipe/images/solutions/hand-landmarks.png)

### 2. Feature Extraction (‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞)
**[EN]** Raw coordinates (x, y) from the camera are not suitable for direct classification due to position and scale variations. The system performs preprocessing:
- **Translation Invariance:** All points are shifted relative to the Wrist (Point 0) so that the hand's position on the screen doesn't affect recognition.
- **Scale Invariance:** Coordinates are normalized by the hand's size to ensure consistent recognition regardless of distance from the camera.

**[TH]** ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏î‡∏¥‡∏ö (x, y) ‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡πÅ‡∏Å‡πà‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏õ‡∏£‡∏õ‡∏£‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÅ‡∏•‡∏∞‡∏Ç‡∏ô‡∏≤‡∏î ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∂‡∏á‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô:
- **‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á (Translation Invariance):** ‡∏¢‡πâ‡∏≤‡∏¢‡∏à‡∏∏‡∏î‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Ç‡πâ‡∏≠‡∏°‡∏∑‡∏≠ (‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà 0) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏°‡∏∑‡∏≠‡∏ö‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å
- **‡πÑ‡∏°‡πà‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î (Scale Invariance):** ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏ù‡πà‡∏≤‡∏°‡∏∑‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á‡πÑ‡∏î‡πâ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏°‡∏∑‡∏≠‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏Å‡∏•‡∏Å‡∏•‡πâ‡∏≠‡∏á

### 3. K-Nearest Neighbors (KNN) Classification
**[EN]** For the "Teachable" feature, the system uses the **K-Nearest Neighbors (KNN)** algorithm. It is a non-parametric, lazy learning algorithm.
- When a user saves a gesture, the extracted feature vector is stored in memory.
- During inference, the system calculates the **Euclidean Distance** between the current hand pose and all stored samples.
- It selects the `K` closest samples (Neighbors) and assigns the class label based on a majority vote.

**[TH]** ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå "‡∏™‡∏≠‡∏ô‡πÑ‡∏î‡πâ" ‡∏£‡∏∞‡∏ö‡∏ö‡πÉ‡∏ä‡πâ‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏° **K-Nearest Neighbors (KNN)** ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡πÅ‡∏ö‡∏ö Lazy Learning
- ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡πà‡∏≤‡∏ó‡∏≤‡∏á ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ (Feature Vector) ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥
- ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì **‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏¢‡∏π‡∏Ñ‡∏•‡∏¥‡∏î (Euclidean Distance)** ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ó‡πà‡∏≤‡∏°‡∏∑‡∏≠‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ
- ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô `K` ‡∏ï‡∏±‡∏ß (Neighbors) ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏Ç‡πâ‡∏≤‡∏á‡∏°‡∏≤‡∏Å (Majority Vote)

---

## üõ† Installation & Usage (‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô)
**Choose one of the following methods:** ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏î‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏ô‡∏∂‡πà‡∏á (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô)

### üü¢ Option 1: Run Locally (‡∏£‡∏±‡∏ô‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á - Recommended)
**Prerequisites:** Python 3.9+, Webcam

1. **Clone Repository:**
   ```bash
   git clone https://github.com/NKSR22/AI-Hand-Gesture-Recognition.git
   cd AI_Count_figer
   ```

2. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Application:**
   ```bash
   python main.py
   ```

---

### üê≥ Option 2: Run with Docker (‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Docker - Advanced)
**[EN]** Running GUI applications with Webcam access in Docker requires **X11 Forwarding** configuration.
**[TH]** ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ GUI ‡πÅ‡∏•‡∏∞ Webcam ‡∏ú‡πà‡∏≤‡∏ô Docker ‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ X11 Forwarding ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Container ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ

#### 0. Install Docker (‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Docker)
‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Docker Desktop ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô
- **Download:** [Docker Desktop for Windows/Mac/Linux](https://www.docker.com/products/docker-desktop/)
- **Verify:** ‡πÄ‡∏õ‡∏¥‡∏î Terminal/CMD ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `docker --version` ‡∏´‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏•‡∏Ç‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ß‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à

#### 1. Clone Repository (‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå)
‡∏Å‡πà‡∏≠‡∏ô‡∏à‡∏∞‡∏£‡∏±‡∏ô Docker Compose ‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô

```bash
git clone https://github.com/NKSR22/AI-Hand-Gesture-Recognition.git
cd AI-Hand-Gesture-Recognition
```

#### 2. Setup X11/Display (‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á)
*‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏° OS ‡∏Ç‡∏≠‡∏á‡∏ó‡πà‡∏≤‡∏ô‡∏Å‡πà‡∏≠‡∏ô*

**ü™ü Windows (WSL2)**
- **Requirement:** [VcXsrv](https://sourceforge.net/projects/vcxsrv/) & [usbipd-win](https://github.com/dorssel/usbipd-win)
- **VcXsrv:** ‡πÄ‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å `Multiple windows` > `Start no client` > ‡∏ï‡∏¥‡πä‡∏Å‡∏ñ‡∏π‡∏Å `Disable access control`
- **WSL:** ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ú‡πà‡∏≤‡∏ô `usbipd wsl attach ...`

**üçé macOS**
- **Requirement:** [XQuartz](https://www.xquartz.org/)
- **Setup:** ‡πÄ‡∏õ‡∏¥‡∏î XQuartz > Preferences > Security > ‡∏ï‡∏¥‡πä‡∏Å‡∏ñ‡∏π‡∏Å `Allow connections from network clients` > Restart Mac
- **Command:** ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `xhost + 127.0.0.1`

**üêß Linux**
- **Command:** ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `xhost +local:docker`

#### 3. Run with Docker Compose (‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°)
**[TH]** ‡πÑ‡∏ü‡∏•‡πå `docker-compose.yml` ‡πÑ‡∏î‡πâ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß (Default ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Windows)

1. **‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå `docker-compose.yml` (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Mac/Linux)**
   - **Windows:** ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
   - **macOS:** ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏õ‡∏¥‡∏î Comment ‡∏Ç‡∏≠‡∏á Windows ‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡∏¥‡∏î Comment ‡∏Ç‡∏≠‡∏á macOS ‡πÅ‡∏ó‡∏ô

2. **‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á**
   ```bash
   docker-compose up --build
   ```

#### 4. Develop & Edit Code (‡∏Å‡∏≤‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î)
‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (Volume Mount) ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á‡∏Å‡∏±‡∏ö Docker ‡πÑ‡∏ß‡πâ‡πÅ‡∏•‡πâ‡∏ß (`.:/app`)

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ú‡πà‡∏≤‡∏ô VS Code (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)**
1. ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå `main.py` ‡∏ö‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì (Windows/Mac) ‡∏î‡πâ‡∏ß‡∏¢ VS Code ‡∏´‡∏£‡∏∑‡∏≠ Text Editor ‡∏ó‡∏µ‡πà‡∏ñ‡∏ô‡∏±‡∏î
2. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÇ‡∏Ñ‡πâ‡∏î‡πÅ‡∏•‡∏∞‡∏Å‡∏î‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å (Save)
3. ‡∏£‡∏±‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á `docker-compose restart` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏Ñ‡πâ‡∏î‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏ô Terminal ‡∏Ç‡∏≠‡∏á Docker**
‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô Container ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á:
1. ‡πÄ‡∏ä‡πá‡∏Ñ ID ‡∏Ç‡∏≠‡∏á Container: `docker ps`
2. ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô Container: `docker exec -it ai-hand-gesture-container bash`
3. ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Nano (‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å): `apt-get update && apt-get install -y nano`
4. ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå: `nano main.py` (‡∏Å‡∏î `Ctrl+X` > `Y` > `Enter` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å)
5. ‡∏£‡∏±‡∏ô‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÉ‡∏´‡∏°‡πà: `python main.py`

---
**¬© 2024 Nakarin Sripanya.** All Rights Reserved.
